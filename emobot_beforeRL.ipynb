{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiiiiiiiiiieve/Rl_emobot/blob/main/emobot_beforeRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSAD6W8Kg_E-"
      },
      "source": [
        "### 실행 후 런타임 다시 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "eS1V2h6Ag6zX",
        "outputId": "a319c33b-27e2-421d-e8ac-266f756a2ffc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiCsYEJUg-Ep"
      },
      "outputs": [],
      "source": [
        "# KoGPT2\n",
        "#모듈 설치\n",
        "\n",
        "!pip install --upgrade transformers\n",
        "!pip uninstall -y pytorch-lightning\n",
        "!pip install pytorch-lightning\n",
        "\n",
        "#KoBERT\n",
        "#모듈 설치\n",
        "\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp==0.8.0\n",
        "!pip install pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf' #허깅페이스\n",
        "!pip install git+https://github.com/SKTBrain/KoBERT.git\n",
        "!pip3 install kobert-transformers\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGanvm7khG6j"
      },
      "source": [
        "### KoGPT2 / 필수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awBy0WWhhGac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "51f8e8e6-e08a-4638-be84-39a72fa23d74"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ec226fbfeb28>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#모듈 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedTokenizerFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: THPDtypeType.tp_dict == nullptr INTERNAL ASSERT FAILED at \"../torch/csrc/Dtype.cpp\":173, please report a bug to PyTorch. "
          ]
        }
      ],
      "source": [
        "#모듈 실행\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "# from pytorch_lightning.core.lightning import LightningModule #모듈 에러 발생해서 우선 보류\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import urllib.request\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import PreTrainedTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXAuaoWAhLcu"
      },
      "outputs": [],
      "source": [
        "#토큰 정의\n",
        "\n",
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "BOS = '</s>'\n",
        "EOS = '</s>'\n",
        "MASK = '<unused0>'\n",
        "SENT = '<unused1>'\n",
        "PAD = '<pad>'\n",
        "\n",
        "#토크나이저/모델 설정\n",
        "\n",
        "# tokenizer_GPT = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
        "# koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "#             bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n",
        "#             pad_token=PAD, mask_token=MASK) #이게 기존 것, 아래는 tokenizer_GPT내용을 쓴 것\n",
        "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
        "model_GPT = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDlSWjMFhpvD"
      },
      "source": [
        "데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfWzNbcyhMVH"
      },
      "outputs": [],
      "source": [
        "#single-turn\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "wellness = pd.read_csv(\"/content/drive/MyDrive/study/EmoBot/우울증/1.dataset/wellness.csv\", encoding = \"cp949\")\n",
        "songys = pd.read_csv(\"/content/drive/MyDrive/study/EmoBot/우울증/1.dataset/songys.csv\", encoding = \"cp949\")\n",
        "\n",
        "wellness = wellness[['utterance(2차) ', 'response(공감)']]\n",
        "wellness.rename(columns = {'utterance(2차) ' : 'utterance'}, inplace = True)\n",
        "wellness.rename(columns = {'response(공감)' : 'response'}, inplace = True)\n",
        "wellness = wellness.dropna(axis=0)\n",
        "\n",
        "songys = songys[['Q', 'A']]\n",
        "songys.rename(columns = {'Q' : 'utterance'}, inplace = True)\n",
        "songys.rename(columns = {'A' : 'response'}, inplace = True)\n",
        "songys = songys.dropna(axis=0)\n",
        "\n",
        "single_data = pd.concat([wellness, songys], axis = 0)\n",
        "single_data.to_csv(\"/content/drive/MyDrive/study/EmoBot/우울증/1.dataset/single_data\") #필요 시 저장\n",
        "single_data\n",
        "\n",
        "single_data = single_data[['utterance', 'response']]\n",
        "single_data\n",
        "\n",
        "#랜덤 추출 (11897개)\n",
        "single_data = single_data.sample(n = 11000)\n",
        "single_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaSg8wGihgRy"
      },
      "outputs": [],
      "source": [
        "data1 = pd.read_csv(\"/content/drive/MyDrive/study/EmoBot/우울증/1.dataset/감성대화말뭉치(최종데이터)_Training_1turn.csv\")\n",
        "#랜덤 추출 (11897개)\n",
        "data1 = data1.sample(n = 40000)\n",
        "\n",
        "data2 = pd.read_csv(\"/content/drive/MyDrive/study/EmoBot/우울증/1.dataset/감성대화말뭉치(최종데이터)_Training_2turn.csv\")\n",
        "#랜덤 추출 (11897개)\n",
        "data2 = data2.sample(n = 50000)\n",
        "\n",
        "data3 = pd.read_csv(\"/content/drive/MyDrive/study/EmoBot/우울증/1.dataset/감성대화말뭉치(최종데이터)_Training_3turn.csv\")\n",
        "#랜덤 추출 (94325개)\n",
        "data3 = data3.sample(n = 42000)\n",
        "\n",
        "multiturn_data = pd.concat([data1, data2, data3], axis = 0)\n",
        "\n",
        "multiturn_data.to_csv(\"/content/drive/MyDrive/study/EmoBot/우울증/1.dataset/감성대화말뭉치(최종데이터)_Training_final.csv\", index=False)\n",
        "multiturn_data= multiturn_data.drop(\"Unnamed: 0\", axis=1)\n",
        "multiturn_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqFHEVBBh11c"
      },
      "outputs": [],
      "source": [
        "emoji_data = pd.concat([single_data, multiturn_data], axis = 0)\n",
        "emoji_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr7QmjCZhk3O"
      },
      "source": [
        "chatbot 클래스 정의, 파라미터 설정 등"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaFNJeX-hr3k"
      },
      "outputs": [],
      "source": [
        "# chatbotdata 만드는 클래스 정의하기\n",
        "\n",
        "class ChatbotDataset(Dataset):\n",
        "    def __init__(self, chats, max_len=256):  # 데이터셋의 전처리를 해주는 부분/max_len 원래 64\n",
        "        self._data = chats\n",
        "        self.max_len = max_len\n",
        "        self.q_token = Q_TKN\n",
        "        self.a_token = A_TKN\n",
        "        self.sent_token = SENT\n",
        "        self.eos = EOS\n",
        "        self.mask = MASK\n",
        "        self.tokenizer = koGPT2_TOKENIZER\n",
        "\n",
        "    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n",
        "        turn = self._data.iloc[idx]\n",
        "        q = turn[\"utterance\"]  # 질문을 가져온다.\n",
        "        q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n",
        "\n",
        "        a = turn[\"response\"]  # 답변을 가져온다.\n",
        "        a = re.sub(r\"([?.!,])\", r\" \", a)  # 구둣점들을 제거한다.\n",
        "\n",
        "        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
        "        q_len = len(q_toked)\n",
        "\n",
        "        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
        "        a_len = len(a_toked)\n",
        "\n",
        "        #질문의 길이가 최대길이보다 크면\n",
        "        if q_len > self.max_len:\n",
        "            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n",
        "            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n",
        "                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로\n",
        "                q_len = len(q_toked)\n",
        "                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n",
        "            a_toked = a_toked[:a_len]\n",
        "            a_len = len(a_toked)\n",
        "\n",
        "        #질문의 길이 + 답변의 길이가 최대길이보다 크면\n",
        "        if q_len + a_len > self.max_len:\n",
        "            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n",
        "            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n",
        "                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로\n",
        "                q_len = len(q_toked)\n",
        "                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n",
        "            a_toked = a_toked[:a_len]\n",
        "            a_len = len(a_toked)\n",
        "\n",
        "        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\n",
        "        labels = [self.mask,] * q_len + a_toked[1:]\n",
        "\n",
        "        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n",
        "        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
        "        # 답변 labels을 index 로 만든다.\n",
        "        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
        "        # 최대길이만큼 PADDING\n",
        "        while len(labels_ids) < self.max_len:\n",
        "            labels_ids += [self.tokenizer.pad_token_id]\n",
        "\n",
        "        # 질문 + 답변을 index 로 만든다.\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
        "        # 최대길이만큼 PADDING\n",
        "        while len(token_ids) < self.max_len:\n",
        "            token_ids += [self.tokenizer.pad_token_id]\n",
        "\n",
        "        #질문+답변, 마스크, 답변\n",
        "        return (token_ids, np.array(mask), labels_ids)\n",
        "\n",
        "#collate_batch 클래스 정의하기\n",
        "\n",
        "def collate_batch(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    mask = [item[1] for item in batch]\n",
        "    label = [item[2] for item in batch]\n",
        "    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1Qu-AOgiEzm"
      },
      "outputs": [],
      "source": [
        "#학습세트 크기 정의하기\n",
        "\n",
        "train_set = ChatbotDataset(emoji_data, max_len=256) #max_len 원래 50\n",
        "#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n",
        "train_dataloader = DataLoader(train_set, batch_size=64, num_workers=0, shuffle=True, collate_fn=collate_batch,)\n",
        "\n",
        "#cpu인지 아닌지 확인하는 코드\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "\n",
        "#아래 코드 해석 못함\n",
        "model_GPT.to(device)\n",
        "model_GPT.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyRE7eekiQ8f"
      },
      "outputs": [],
      "source": [
        "#학습 파라미터 설정\n",
        "\n",
        "learning_rate = 3e-5\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "optimizer = torch.optim.Adam(model_GPT.parameters(), lr=learning_rate)\n",
        "epoch = 10 #multi = 10, single = 55\n",
        "Sneg = -1e18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKOE6l-Uicj7"
      },
      "source": [
        "### KoGPT2 / 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWiZpRTGiWTP"
      },
      "outputs": [],
      "source": [
        "# # 학습\n",
        "\n",
        "# print(\"start\")\n",
        "# for epoch in range(epoch):  # 반복 횟수 변수인 epoch가 정의되어야 합니다.\n",
        "#     for batch_idx, samples in enumerate(train_dataloader):\n",
        "#         optimizer.zero_grad()\n",
        "#         token_ids, mask, label = samples\n",
        "#         token_ids = token_ids.to(device)  # 입력 데이터를 GPU로 보냅니다.\n",
        "#         mask = mask.to(device)  # 입력 데이터를 GPU로 보냅니다.\n",
        "#         label = label.to(device)  # 입력 데이터를 GPU로 보냅니다.\n",
        "#         out = model_GPT(token_ids)\n",
        "#         out = out.logits\n",
        "#         mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
        "#         mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
        "#         loss = criterion(mask_out.transpose(2, 1), label)\n",
        "#         avg_loss = loss.sum() / mask.sum()\n",
        "#         avg_loss.backward()\n",
        "#         optimizer.step()\n",
        "# print(\"end\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_bZcJoeiXta"
      },
      "outputs": [],
      "source": [
        "# # 모델 상태 저장\n",
        "# torch.save(model_GPT.state_dict(), '/content/drive/MyDrive/study/EmoBot/우울증/2.code/kogpt2_model_final.pth')\n",
        "\n",
        "# # Optimizer 상태도 저장하려면 아래와 같이 추가합니다.\n",
        "# torch.save(optimizer.state_dict(), '/content/drive/MyDrive/study/EmoBot/우울증/2.code/optimizer_final.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FERemOl4id3J"
      },
      "source": [
        "### KoGPT2 / 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aya70wDIiYgZ"
      },
      "outputs": [],
      "source": [
        "# 모델 상태 불러오기 (wellness, corpus)\n",
        "model_GPT = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')  # 모델 클래스를 생성\n",
        "model_GPT.load_state_dict(torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/kogpt2_model_final.pth'))\n",
        "model_GPT.eval()  # 추론 모드로 전환\n",
        "\n",
        "# Optimizer 상태를 불러오려면 아래와 같이 추가합니다.\n",
        "optimizer.load_state_dict(torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/optimizer_final.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhU3MkXvMi69"
      },
      "outputs": [],
      "source": [
        "# # 두 가지 모델, 옵티마이저 병합\n",
        "\n",
        "# import torch\n",
        "\n",
        "# # 첫 번째 모델 및 옵티마이저 상태 불러오기\n",
        "# model1_state = torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/kogpt2_model.pth')\n",
        "# optimizer1_state = torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/optimizer.pth')\n",
        "\n",
        "# # 두 번째 모델 및 옵티마이저 상태 불러오기\n",
        "# model2_state = torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/kogpt2_model_final.pth')\n",
        "# optimizer2_state = torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/optimizer_final.pth')\n",
        "\n",
        "# # 두 모델 상태를 병합\n",
        "# combined_model_state = {\n",
        "#     'model_state_dict': model1_state,\n",
        "#     'model_state_dict_2': model2_state\n",
        "# }\n",
        "\n",
        "# # 모델 상태를 별도의 파일로 저장\n",
        "# torch.save(model_GPT.state_dict(), '/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/combined_model_single_multi.pth')\n",
        "\n",
        "# # 두 옵티마이저 상태를 병합\n",
        "# combined_optimizer_state = {\n",
        "#     'optimizer_state_dict': optimizer1_state,\n",
        "#     'optimizer_state_dict_2': optimizer2_state\n",
        "# }\n",
        "\n",
        "# # 옵티마이저 상태를 별도의 파일로 저장\n",
        "# torch.save(optimizer.state_dict(), '/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/combined_optimizer_single_multi.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM-nGwPqSQTy"
      },
      "source": [
        "### KoGPT2 / 대화 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrz-BMvISSf2"
      },
      "outputs": [],
      "source": [
        "# # 모델을 GPU로 이동\n",
        "# model_GPT.to('cuda:0')\n",
        "\n",
        "# import csv\n",
        "\n",
        "# # CSV 파일 경로\n",
        "# csv_file = '/content/drive/MyDrive/study/EmoBot/우울증/3.result/kogpt2_result(wellness, songys, corpus).csv'\n",
        "\n",
        "# # CSV 파일에 대화 데이터 저장을 위한 함수\n",
        "# def save_conversation_to_csv(conversation_data):\n",
        "#     with open(csv_file, 'a', newline='') as file:\n",
        "#         fieldnames = ['kogpt2_utterance', 'kogpt2_response']\n",
        "#         writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "#         if file.tell() == 0:  # 파일이 비어 있는 경우에만 헤더를 작성\n",
        "#             writer.writeheader()\n",
        "#         writer.writerow(conversation_data)\n",
        "\n",
        "# # 대화 데이터 초기화\n",
        "# conversation_data = {\n",
        "#     'kogpt2_utterance': '',\n",
        "#     'kogpt2_response': '',\n",
        "# }\n",
        "\n",
        "# # 대화 예시 추출\n",
        "# print(\"안녕하세요!\\n\")\n",
        "# name = input(\"사용자님의 성함을 말씀해주세요:\")\n",
        "# print(f'\\n{name}님 안녕하세요.\\nChatbot과 함께 대화를 나눠보아요.\\n대화 종료를 원할 경우, quit를 입력해주세요.\\n')\n",
        "\n",
        "# while True:\n",
        "#     kogpt2_utterance = input(\"user > \").strip()\n",
        "#     if kogpt2_utterance == \"quit\":\n",
        "#         print(f'{name}님 대화를 종료하겠습니다.')\n",
        "#         break\n",
        "\n",
        "#     conversation_data['kogpt2_utterance'] = kogpt2_utterance\n",
        "\n",
        "#     kogpt2_response = \"\"\n",
        "#     while True:\n",
        "#         input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(\"<usr>\"+ kogpt2_utterance + \"<unused1>\" + \"<sys>\" + kogpt2_response)).unsqueeze(dim=0).to(device)\n",
        "#         pred = model_GPT(input_ids)\n",
        "#         pred = pred.logits\n",
        "#         gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
        "#         if gen == \"</s>\":\n",
        "#             break\n",
        "#         kogpt2_response += gen.replace(\"▁\", \" \")\n",
        "#         if \"00\" in kogpt2_response:\n",
        "#             kogpt2_response = kogpt2_response.replace(\"00\", \"사용자\")\n",
        "\n",
        "#     conversation_data['kogpt2_response'] = kogpt2_response\n",
        "\n",
        "#     print(f\"Chatbot > {kogpt2_response.strip()}\\n\")\n",
        "#     print(\"\\n\")\n",
        "#     # 대화 데이터를 CSV 파일에 추가\n",
        "#     save_conversation_to_csv(conversation_data)\n",
        "\n",
        "# # CSV 파일 닫기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #csv 내 데이터 있는지 확인 코드\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# if emoji_data['utterance'].str.contains('더 후회하기 전에 사과하세요').any():\n",
        "#     print(\"데이터가 존재합니다.\")\n",
        "# else:\n",
        "#     print(\"데이터가 존재하지 않습니다.\")"
      ],
      "metadata": {
        "id": "NvxicRQMrGSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import csv\n",
        "import random  # 랜덤 샘플링을 위한 라이브러리 추가\n",
        "\n",
        "# 모델을 GPU로 이동\n",
        "model_GPT.to('cuda:0')\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file = '/content/drive/MyDrive/study/EmoBot/우울증/3.result/kogpt2_result_crawling.csv'\n",
        "\n",
        "# CSV 파일에 대화 데이터 저장을 위한 함수\n",
        "def save_conversation_to_csv(conversation_data):\n",
        "    with open(csv_file, 'a', newline='') as file:\n",
        "        fieldnames = ['kogpt2_utterance', 'kogpt2_response']\n",
        "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "        if file.tell() == 0:  # 파일이 비어 있는 경우에만 헤더를 작성\n",
        "            writer.writeheader()\n",
        "        writer.writerow(conversation_data)\n",
        "\n",
        "# emoji_data에서 랜덤으로 1000개 추출\n",
        "random_samples = emoji_data['utterance'].dropna().sample(1000)\n",
        "\n",
        "# 대화 예시 추출\n",
        "print(\"안녕하세요!\\n\")\n",
        "name = input(\"사용자님의 성함을 말씀해주세요:\")\n",
        "print(f'\\n{name}님 안녕하세요.\\nChatbot과 함께 대화를 나눠보아요.\\n대화 종료를 원할 경우, quit를 입력해주세요.\\n')\n",
        "\n",
        "for utterance_value in random_samples:  # 랜덤으로 추출한 1000개에 대해 반복\n",
        "    conversation_data = {\n",
        "        'kogpt2_utterance': utterance_value,\n",
        "        'kogpt2_response': '',\n",
        "    }\n",
        "\n",
        "    kogpt2_response = \"\"\n",
        "    while True:\n",
        "        input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(\"<usr>\"+ utterance_value + \"<unused1>\" + \"<sys>\" + kogpt2_response)).unsqueeze(dim=0).to(device)\n",
        "        pred = model_GPT(input_ids)\n",
        "        pred = pred.logits\n",
        "        gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
        "        if gen == \"</s>\":\n",
        "            break\n",
        "        kogpt2_response += gen.replace(\"▁\", \" \")\n",
        "        if \"00\" in kogpt2_response:\n",
        "            kogpt2_response = kogpt2_response.replace(\"00\", \"사용자\")\n",
        "\n",
        "    conversation_data['kogpt2_response'] = kogpt2_response\n",
        "\n",
        "    # Chatbot의 답변과 사용자의 입력을 출력\n",
        "    print(f\"user> {utterance_value}\")\n",
        "    print(f\"Chatbot > {kogpt2_response.strip()}\\n\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # 대화 데이터를 CSV 파일에 추가\n",
        "    save_conversation_to_csv(conversation_data)\n",
        "\n",
        "print(f'{name}님 대화를 종료하겠습니다.')"
      ],
      "metadata": {
        "id": "Gkw32qjepNUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgTbk4k_ZgoA"
      },
      "source": [
        "# **KoBERT**\n",
        "\n",
        "\n",
        "*   학습은 corpus로 진행하기\n",
        "*   입력은 KoGPT2의 답변으로 하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD9ZpMoqBmoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c5fb9b-2edf-42bb-fbf9-5928201e9969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
            "  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"
          ]
        }
      ],
      "source": [
        "#모듈 실행\n",
        "\n",
        "import gluonnlp as nlp\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbOuXLW9Bmoi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "45cbedd489e14212bf9bcb9dc5a62f99",
            "ae91b7224dcd44ef8ace2901a775da4c",
            "1b3151483dd546afabb1bdfe8661914b",
            "e2bdc8da308e4feca349fc75e194f351",
            "3593dabf91a54f8c9e39f47d2cbce4da",
            "409ab0c5abba4d6680d905452d1bb57d",
            "17dcea2ede8f4c20814d6f8e14bf96db",
            "f3faca4943b941ac872bdc2ded9e7bb0",
            "73eae158bfaa402e94dbdc3024d71db3",
            "fb90b222032449d197130da74c2541a0",
            "9d6042f807f143f99b6a40f8a4c2fb34",
            "b1b75b80cd034c5db775d06b8334f6a1",
            "42e67c36ac4b4e2eb9e5400e5706ace8",
            "5b79ebbc25d64f33a8bcb42298a4036d",
            "6acd44385a084dd1b45c5bbb6a0b4699",
            "e5e4706c0b824e7abc51bea5462b7209",
            "180e0b5de7d94fd290074cbfb5172fbf",
            "4e6926d5c66443fe972be4e99a5b5c5a",
            "d9118ae0d0cc47ee822b894e60b2da89",
            "7215d11003e542f9b809da4a08740967",
            "7b0e8fb7d0e64af9b4053f19976454de",
            "8a648b9e904446b38548aa1b98fd99f0",
            "8f2b844344ac40f5a81d6a872cf05a75",
            "7d89744cb2364b3bb70da385af3165ce",
            "dac026d5bc9c4dadb151c452663c544b",
            "297a90d4c4cc44f5853c2871825cb90a",
            "aa89ef83a4714d55a929404d29278dc7",
            "67489c89ab10406297c7b8aa819d86ad",
            "615fbe87113348378acdd0467a2db663",
            "0288048dbac342cd8d703c5e38a95392",
            "a3fe1bc9c80d450db31640dbf2784c85",
            "6f3b36cb6214415683419509bb3dce42",
            "d8874a42e1e74fc9a4868d4b421e18b7",
            "51cbbcda0ce84d92962cb3af133c5ef3",
            "7ef658b4e1454646bdbcf252941f7ce4",
            "657f4e744dea408492df0bf136268300",
            "b809c6f657bb48f08b820b16d186a495",
            "ea10927e554b4843a111d1d375e9c21c",
            "fd0c37c25fa14de8a9a1da4522fcd91c",
            "afd1fc6c76524e008afe57e42fc99819",
            "830d49621a4e43279d9ce83d88e3eacc",
            "6d843ec958df4f958d2f40754d4551eb",
            "cd4a30c641464ba2b718be8c8a167d90",
            "fbfcce981fa04bbba3565e4fa6d2b906",
            "d387077b52074a35ae9f181db38fbdf6",
            "271fe8ac1cac406faad2cb479d712b67",
            "f7d682d50a5d43cfbb15d4227ecb370c",
            "862f4bc125b14b66a77d245bc3c5843c",
            "36e62cdd90e1414c8940f7c0f3b521db",
            "b9ba85958b354dc3885f1cddfb508d11",
            "8dcafb7bf42b41969d8ceb2d44633c2d",
            "f0a07afa82c147058c3552df7d668bbc",
            "acdf3535d41c45d48280bbfd564bc736",
            "956ba4bdd2a048229bbc8942ad981d3a",
            "333a58a3d87e4ca1bb2f9179d23fc8d4"
          ]
        },
        "outputId": "b4320b92-ebb3-4d7b-d868-1c5b018e574c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45cbedd489e14212bf9bcb9dc5a62f99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/371k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1b75b80cd034c5db775d06b8334f6a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f2b844344ac40f5a81d6a872cf05a75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
            "The class this function is called from is 'KoBERTTokenizer'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/535 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51cbbcda0ce84d92962cb3af133c5ef3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/369M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d387077b52074a35ae9f181db38fbdf6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#cpu 여부 확인\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "\n",
        "#토크나이저/모델/보캡 설정\n",
        "\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtU2BF7tBmoi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "227249f8-722a-467e-820e-3cd706d304f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Sentence Emotion  Unnamed: 2  \\\n",
              "0                               언니 동생으로 부르는게 맞는 일인가요..??      공포         NaN   \n",
              "1                                           그냥 내 느낌일뿐겠지?      공포         NaN   \n",
              "2                                         아직너무초기라서 그런거죠?      공포         NaN   \n",
              "3                                          유치원버스 사고 낫다던데      공포         NaN   \n",
              "4                                            근데 원래이런거맞나요      공포         NaN   \n",
              "...                                                  ...     ...         ...   \n",
              "38589               솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라..      혐오         NaN   \n",
              "38590                                        재미가 없으니 망하지      혐오         NaN   \n",
              "38591  공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...      혐오         NaN   \n",
              "38592               코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스 ㅉㅉㅉ      혐오         NaN   \n",
              "38593               와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요      혐오         NaN   \n",
              "\n",
              "       Unnamed: 3  Unnamed: 4   공포    5468  \n",
              "0             NaN         NaN   놀람  5898.0  \n",
              "1             NaN         NaN   분노  5665.0  \n",
              "2             NaN         NaN   슬픔  5267.0  \n",
              "3             NaN         NaN   중립  4830.0  \n",
              "4             NaN         NaN   행복  6037.0  \n",
              "...           ...         ...  ...     ...  \n",
              "38589         NaN         NaN  NaN     NaN  \n",
              "38590         NaN         NaN  NaN     NaN  \n",
              "38591         NaN         NaN  NaN     NaN  \n",
              "38592         NaN         NaN  NaN     NaN  \n",
              "38593         NaN         NaN  NaN     NaN  \n",
              "\n",
              "[38594 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d12eef5c-e41f-4682-b2cb-9909a0f926bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>공포</th>\n",
              "      <th>5468</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>언니 동생으로 부르는게 맞는 일인가요..??</td>\n",
              "      <td>공포</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>놀람</td>\n",
              "      <td>5898.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>그냥 내 느낌일뿐겠지?</td>\n",
              "      <td>공포</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>분노</td>\n",
              "      <td>5665.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>아직너무초기라서 그런거죠?</td>\n",
              "      <td>공포</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>5267.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>유치원버스 사고 낫다던데</td>\n",
              "      <td>공포</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>중립</td>\n",
              "      <td>4830.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>근데 원래이런거맞나요</td>\n",
              "      <td>공포</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>행복</td>\n",
              "      <td>6037.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38589</th>\n",
              "      <td>솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라..</td>\n",
              "      <td>혐오</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38590</th>\n",
              "      <td>재미가 없으니 망하지</td>\n",
              "      <td>혐오</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38591</th>\n",
              "      <td>공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...</td>\n",
              "      <td>혐오</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38592</th>\n",
              "      <td>코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스 ㅉㅉㅉ</td>\n",
              "      <td>혐오</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38593</th>\n",
              "      <td>와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요</td>\n",
              "      <td>혐오</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38594 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d12eef5c-e41f-4682-b2cb-9909a0f926bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d12eef5c-e41f-4682-b2cb-9909a0f926bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d12eef5c-e41f-4682-b2cb-9909a0f926bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37ba0b6e-ae62-4e30-8962-fa97de288431\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37ba0b6e-ae62-4e30-8962-fa97de288431')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37ba0b6e-ae62-4e30-8962-fa97de288431 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b0f51830-cc50-431d-a3c2-0f9de7410baa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('corpus_emotion')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b0f51830-cc50-431d-a3c2-0f9de7410baa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('corpus_emotion');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "corpus_emotion = pd.read_excel(\"/content/drive/MyDrive/study/EmoBot/우울증/1.dataset/한국어단발성대화데이터셋.xlsx\")\n",
        "corpus_emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKkf7z7EBmoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767f90a0-32ba-451f-fe3f-17d9435d4c23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "행복    6037\n",
              "놀람    5898\n",
              "분노    5665\n",
              "공포    5468\n",
              "혐오    5429\n",
              "슬픔    5267\n",
              "중립    4830\n",
              "Name: Emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "corpus_emotion['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUASyAoXBmoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dee5948-021f-4d2b-fd69-d253da9cde7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 감정 비율:\n",
            "행복    4225\n",
            "놀람    4128\n",
            "분노    3965\n",
            "공포    3827\n",
            "혐오    3800\n",
            "슬픔    3686\n",
            "중립    3381\n",
            "Name: Emotion, dtype: int64\n",
            "\n",
            "테스트 데이터의 감정 비율:\n",
            "행복    1812\n",
            "놀람    1770\n",
            "분노    1700\n",
            "공포    1641\n",
            "혐오    1629\n",
            "슬픔    1581\n",
            "중립    1449\n",
            "Name: Emotion, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#테스트 정확도가 너무 낮아서 7:3 비율로 진행해보기\n",
        "train_ratio = 0.7\n",
        "test_ratio = 0.3\n",
        "\n",
        "# 각각의 감정에 대한 인덱스를 추출합니다.\n",
        "emotion_행복 = corpus_emotion[corpus_emotion['Emotion'] == '행복']\n",
        "emotion_놀람 = corpus_emotion[corpus_emotion['Emotion'] == '놀람']\n",
        "emotion_분노 = corpus_emotion[corpus_emotion['Emotion'] == '분노']\n",
        "emotion_공포 = corpus_emotion[corpus_emotion['Emotion'] == '공포']\n",
        "emotion_혐오 = corpus_emotion[corpus_emotion['Emotion'] == '혐오']\n",
        "emotion_슬픔 = corpus_emotion[corpus_emotion['Emotion'] == '슬픔']\n",
        "emotion_중립 = corpus_emotion[corpus_emotion['Emotion'] == '중립']\n",
        "\n",
        "train_emotion_행복, test_emotion_행복 = train_test_split(emotion_행복, test_size=test_ratio, random_state=42)\n",
        "train_emotion_놀람, test_emotion_놀람 = train_test_split(emotion_놀람, test_size=test_ratio, random_state=42)\n",
        "train_emotion_분노, test_emotion_분노 = train_test_split(emotion_분노, test_size=test_ratio, random_state=42)\n",
        "train_emotion_공포, test_emotion_공포 = train_test_split(emotion_공포, test_size=test_ratio, random_state=42)\n",
        "train_emotion_혐오, test_emotion_혐오 = train_test_split(emotion_혐오, test_size=test_ratio, random_state=42)\n",
        "train_emotion_슬픔, test_emotion_슬픔 = train_test_split(emotion_슬픔, test_size=test_ratio, random_state=42)\n",
        "train_emotion_중립, test_emotion_중립 = train_test_split(emotion_중립, test_size=test_ratio, random_state=42)\n",
        "\n",
        "dataset_train = pd.concat([train_emotion_행복, train_emotion_놀람, train_emotion_분노, train_emotion_공포, train_emotion_혐오, train_emotion_슬픔, train_emotion_중립], axis = 0)\n",
        "dataset_test = pd.concat([test_emotion_행복, test_emotion_놀람, test_emotion_분노, test_emotion_공포, test_emotion_혐오, test_emotion_슬픔, test_emotion_중립], axis = 0)\n",
        "\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터의 감정 비율을 확인합니다.\n",
        "print(\"훈련 데이터의 감정 비율:\")\n",
        "print(dataset_train['Emotion'].value_counts())\n",
        "print(\"\\n테스트 데이터의 감정 비율:\")\n",
        "print(dataset_test['Emotion'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm8Dfcb4Bmoj"
      },
      "outputs": [],
      "source": [
        "# depressed_data.loc[(depressed_data['감정'] == \"지속되는우울한기분(우울감)\"), '감정'] = 0 와 같은 형태로 라벨링\n",
        "#'분노', '기쁨', '불안', '당황', '슬픔', '상처' (감성 말뭉치 기준)\n",
        "\n",
        "dataset_train.loc[(dataset_train['Emotion'] == '행복'), 'Emotion'] = 0\n",
        "dataset_train.loc[(dataset_train['Emotion'] == '놀람'), 'Emotion'] = 1\n",
        "dataset_train.loc[(dataset_train['Emotion'] == '분노'), 'Emotion'] = 2\n",
        "dataset_train.loc[(dataset_train['Emotion'] == '공포'), 'Emotion'] = 3\n",
        "dataset_train.loc[(dataset_train['Emotion'] == '혐오'), 'Emotion'] = 4\n",
        "dataset_train.loc[(dataset_train['Emotion'] == '슬픔'), 'Emotion'] = 5\n",
        "dataset_train.loc[(dataset_train['Emotion'] == '중립'), 'Emotion'] = 6\n",
        "\n",
        "dataset_test.loc[(dataset_test['Emotion'] == '행복'), 'Emotion'] = 0\n",
        "dataset_test.loc[(dataset_test['Emotion'] == '놀람'), 'Emotion'] = 1\n",
        "dataset_test.loc[(dataset_test['Emotion'] == '분노'), 'Emotion'] = 2\n",
        "dataset_test.loc[(dataset_test['Emotion'] == '공포'), 'Emotion'] = 3\n",
        "dataset_test.loc[(dataset_test['Emotion'] == '혐오'), 'Emotion'] = 4\n",
        "dataset_test.loc[(dataset_test['Emotion'] == '슬픔'), 'Emotion'] = 5\n",
        "dataset_test.loc[(dataset_test['Emotion'] == '중립'), 'Emotion'] = 6\n",
        "\n",
        "#리스트 생성\n",
        "\n",
        "dataset_train_list = []\n",
        "for ques1, label1 in zip(dataset_train['Sentence'], dataset_train['Emotion']):\n",
        "    data_item1 = []\n",
        "    data_item1.append(ques1)\n",
        "    data_item1.append(str(label1))\n",
        "    dataset_train_list.append(data_item1)\n",
        "\n",
        "dataset_test_list = []\n",
        "for ques2, label2 in zip(dataset_test['Sentence'], dataset_test['Emotion']):\n",
        "    data_item2 = []\n",
        "    data_item2.append(ques2)\n",
        "    data_item2.append(str(label2))\n",
        "    dataset_test_list.append(data_item2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz6rfCN3Bmok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f28c835-8c79-4062-8167-058de477b3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27012\n",
            "11582\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset_train_list))\n",
        "print(len(dataset_test_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9oi_P-ABmok"
      },
      "outputs": [],
      "source": [
        "#데이터 분할\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state=34)\n",
        "dataset_train = dataset_train_list\n",
        "dataset_test = dataset_test_list\n",
        "\n",
        "#파라미터 설정\n",
        "\n",
        "max_len = 256 #원래 64\n",
        "batch_size = 128 #loss 줄이기 위해 높여보기\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 55 #loss 줄이기 위해 높여보기\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5 #loss 줄이기 위해 낮춰보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDnuftM4Bmok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6662ff1f-89ba-4a97-ac4a-ddda6382c61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([  2, 529,   3, 589,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "         1,   1,   1,   1,   1,   1,   1,   1,   1]), array([256]), array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-b99c8ca88001>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m#모델 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbertmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdr_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m# 아래 코드 해석 못함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "#bert 데이터셋 만드는 클래스 정의하기\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_len, pad=True, pair=False):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.pad = pad\n",
        "        self.pair = pair\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.pair:\n",
        "            text = self.dataset[idx][0][0]\n",
        "            text_pair = self.dataset[idx][0][1]\n",
        "        else:\n",
        "            text = self.dataset[idx][0]\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            text_pair if self.pair else None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=self.pad,\n",
        "            truncation=False\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(inputs['input_ids']),\n",
        "            'attention_mask': torch.tensor(inputs['attention_mask']),\n",
        "            'token_type_ids': torch.tensor(inputs['token_type_ids'])\n",
        "        }\n",
        "\n",
        "        item['labels'] = int(self.dataset[idx][1])\n",
        "\n",
        "        # 패딩된 시퀀스/길이와 타입에 대한 내용/어텐션 마스크 시퀀스 세 가지 배열을 얻을 수 있도록 함\n",
        "        padded_seq = torch.tensor(inputs['input_ids']).numpy()\n",
        "        len_and_type = list(torch.tensor(inputs['token_type_ids']).shape) #dtype은 출력 안됨\n",
        "        attention_mask_seq = torch.tensor(inputs['attention_mask']).numpy()\n",
        "\n",
        "        return np.array(padded_seq), np.array(len_and_type), np.array(attention_mask_seq), item['labels']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = BERTDataset(dataset_train, tokenizer, max_len, True, True)\n",
        "test_dataset = BERTDataset(dataset_test, tokenizer, max_len, True, True)\n",
        "\n",
        "# 데이터로더 생성\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#학습 데이터셋 예시 추출해보기\n",
        "\n",
        "print(train_dataset[0])\n",
        "\n",
        "#bert 분류하는 클래스 정의하기\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=7,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)\n",
        "\n",
        "#모델 정의\n",
        "\n",
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
        "\n",
        "# 아래 코드 해석 못함\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_loader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOoZrsIFBmok"
      },
      "outputs": [],
      "source": [
        "# train_history = []\n",
        "# test_history = []\n",
        "# loss_history = []\n",
        "\n",
        "# for e in range(num_epochs):\n",
        "#     train_acc = 0.0\n",
        "#     test_acc = 0.0\n",
        "#     model.train()\n",
        "#     for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_loader)):\n",
        "#         optimizer.zero_grad()\n",
        "#         token_ids = token_ids.long().to(device)\n",
        "#         segment_ids = segment_ids.long().to(device)\n",
        "#         valid_length= valid_length\n",
        "#         label = label.long().to(device)\n",
        "#         out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "#         # print(label.shape, out.shape)\n",
        "#         loss = loss_fn(out, label)\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()  # Update learning rate schedule\n",
        "#         train_acc += calc_accuracy(out, label)\n",
        "#         if batch_id % log_interval == 0:\n",
        "#             print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "#             train_history.append(train_acc / (batch_id+1))\n",
        "#             loss_history.append(loss.data.cpu().numpy())\n",
        "#     print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "#     # train_history.append(train_acc / (batch_id+1))\n",
        "\n",
        "#     # .eval() : nn.Module에서 train time과 eval time에서 수행하는 다른 작업을 수행할 수 있도록 switching 하는 함수\n",
        "#     # 즉, model이 Dropout이나 BatNorm2d를 사용하는 경우, train 시에는 사용하지만 evaluation을 할 때에는 사용하지 않도록 설정해주는 함수\n",
        "#     model.eval()\n",
        "#     for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_loader)):\n",
        "#         token_ids = token_ids.long().to(device)\n",
        "#         segment_ids = segment_ids.long().to(device)\n",
        "#         valid_length = valid_length\n",
        "#         label = label.long().to(device)\n",
        "#         out = model(token_ids, valid_length, segment_ids)\n",
        "#         test_acc += calc_accuracy(out, label)\n",
        "#     print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "#     test_history.append(test_acc / (batch_id+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3a0OWAMKcL7"
      },
      "outputs": [],
      "source": [
        "# # 모델 상태 저장\n",
        "# torch.save(model.state_dict(), '/content/drive/MyDrive/study/EmoBot/우울증/2.code/kobert_classifier_model.pth')\n",
        "\n",
        "# # Optimizer 상태도 저장하려면 아래와 같이 추가합니다.\n",
        "# torch.save(optimizer.state_dict(), '/content/drive/MyDrive/study/EmoBot/우울증/2.code/optimizer_KoBERT.pth')\n",
        "\n",
        "# # train_history, test_history, loss_history 저장\n",
        "# import pickle\n",
        "\n",
        "# with open('/content/drive/MyDrive/study/EmoBot/우울증/2.code/train_history.pkl', 'wb') as f:\n",
        "#     pickle.dump(train_history, f)\n",
        "\n",
        "# with open('/content/drive/MyDrive/study/EmoBot/우울증/2.code/test_history.pkl', 'wb') as f:\n",
        "#     pickle.dump(test_history, f)\n",
        "\n",
        "# with open('/content/drive/MyDrive/study/EmoBot/우울증/2.code/loss_history.pkl', 'wb') as f:\n",
        "#     pickle.dump(loss_history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZNrek75KwVT"
      },
      "outputs": [],
      "source": [
        "# 모델 상태 불러오기\n",
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/kobert_classifier_model.pth'))\n",
        "model.eval()  # 추론 모드로 전환\n",
        "\n",
        "# Optimizer 상태를 불러오려면 아래와 같이 추가합니다.\n",
        "optimizer.load_state_dict(torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/optimizer_KoBERT.pth'))\n",
        "\n",
        "# train_history, test_history, loss_history 불러오기\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/train_history.pkl', 'rb') as f:\n",
        "    train_history = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/test_history.pkl', 'rb') as f:\n",
        "    test_history = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/study/EmoBot/우울증/2.code/1. 저장 완료/loss_history.pkl', 'rb') as f:\n",
        "    loss_history = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 감정 이모티콘 데이터\n",
        "emoticon_label = {\n",
        "    'happy': ['😄', '😃', '😁', '😆', '😉', '😊', '😋'],\n",
        "    'surprised': ['😲', '😮', '😯'],\n",
        "    'angry': ['😡', '😠', '🤬', '😤'],\n",
        "    'fear': ['😦', '😧', '😨'],\n",
        "    'disgust': ['😫', '😩', '😣'],\n",
        "    'sad': ['😢', '😞', '😔', '😢', '☹️', '🙁', '🥺', '😭'],\n",
        "    'neutral': ['😗', '🙂', '😙', '😚']\n",
        "}\n",
        "\n",
        "#감정 예측하는 함수 정의\n",
        "\n",
        "def emoticon_predict(predict_sentence):\n",
        "\n",
        "    #함수 밖에서 정의\n",
        "    # emoticon_label = {\n",
        "    #     'happy': ['😄', '😃', '😁', '😆', '😉', '😊', '😋'],\n",
        "    #     'surprised': ['😲', '😮', '😯'],\n",
        "    #     'angry': ['😡', '😠', '🤬', '😤'],\n",
        "    #     'fear': ['😦', '😧', '😨'],\n",
        "    #     'disgust': ['😫', '😩', '😣'],\n",
        "    #     'sad': ['😢', '😞', '😔', '😢', '☹️', '🙁', '🥺', '😭'],\n",
        "    #     'neutral': ['😗', '🙂', '😙', '😚']\n",
        "    # }\n",
        "\n",
        "    data = [predict_sentence, '0']\n",
        "    dataset_another = [data]\n",
        "\n",
        "    another_test = BERTDataset(dataset_another, tokenizer, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "        valid_length = valid_length\n",
        "        label = label.long().to(device)\n",
        "\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "        emoticon_add = []\n",
        "        for i in out:\n",
        "            logits = i\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "            #분노 기쁨 슬픔만 진행하는 것도 고려해보기\n",
        "            #에크만 참고해서 7가지로 분류\n",
        "            if np.argmax(logits) == 0:\n",
        "                # emotion = \"행복이\"\n",
        "                emoticon_select = random.choice(emoticon_label['happy'])\n",
        "                emoticon_add.append(emoticon_select)\n",
        "            elif np.argmax(logits) == 1:\n",
        "                # emotion = \"놀람이\"\n",
        "                emoticon_select = random.choice(emoticon_label['surprised'])\n",
        "                emoticon_add.append(emoticon_select)\n",
        "            elif np.argmax(logits) == 2:\n",
        "                # emotion = \"분노가\"\n",
        "                emoticon_select = random.choice(emoticon_label['angry'])\n",
        "                emoticon_add.append(emoticon_select)\n",
        "            elif np.argmax(logits) == 3:\n",
        "                # emotion = \"공포가\"\n",
        "                emoticon_select = random.choice(emoticon_label['fear'])\n",
        "                emoticon_add.append(emoticon_select)\n",
        "            elif np.argmax(logits) == 4:\n",
        "                # emotion = \"혐오가\"\n",
        "                emoticon_select = random.choice(emoticon_label['disgust'])\n",
        "                emoticon_add.append(emoticon_select)\n",
        "            elif np.argmax(logits) == 5:\n",
        "                # emotion = \"슬픔이\"\n",
        "                emoticon_select = random.choice(emoticon_label['sad'])\n",
        "                emoticon_add.append(emoticon_select)\n",
        "            elif np.argmax(logits) == 6:\n",
        "                # emotion = \"중립이\"\n",
        "                emoticon_select = random.choice(emoticon_label['neutral'])\n",
        "                emoticon_add.append(emoticon_select)\n",
        "\n",
        "            return emoticon_add"
      ],
      "metadata": {
        "id": "RDIPpNEe_4zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4vL_WmY5QTl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import csv\n",
        "import random\n",
        "\n",
        "# 모델을 GPU로 이동\n",
        "model_GPT.to('cuda:0')\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file = '/content/drive/MyDrive/study/EmoBot/우울증/3.result/emobot_result_crawling.csv'\n",
        "\n",
        "# CSV 파일에 대화 데이터 저장을 위한 함수\n",
        "def save_conversation_to_csv(conversation_data_emobot):\n",
        "    with open(csv_file, 'a', newline='') as file:\n",
        "        fieldnames = ['emobot_utterance', 'emobot_response']\n",
        "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "        if file.tell() == 0:  # 파일이 비어 있는 경우에만 헤더를 작성\n",
        "            writer.writeheader()\n",
        "        writer.writerow(conversation_data_emobot)\n",
        "\n",
        "# 대화 데이터 초기화\n",
        "conversation_data_emobot = {\n",
        "    'emobot_utterance': '',\n",
        "    'emobot_response': '',\n",
        "}\n",
        "\n",
        "# 경고 무시 설정\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# 대화 예시 추출\n",
        "print(\"안녕하세요!\\n\")\n",
        "name = str(input(\"사용자님의 성함을 말씀해주세요:\"))\n",
        "print(\"\\n\")\n",
        "print(f'{name}님 안녕하세요.😊\\nEmoBot🤖과 함께 대화를 나눠보아요.\\n대화 종료를 원할 경우, quit를 입력해주세요.')\n",
        "print(\"\\n\")\n",
        "\n",
        "# emoji_data에서 랜덤으로 1000개 추출\n",
        "random_samples = emoji_data['utterance'].dropna().sample(1000)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for emobot_utterance in random_samples:  # 랜덤으로 추출한 1000개에 대해 반복\n",
        "        all_emobot_conversation.append(emobot_utterance)\n",
        "        if emobot_utterance == \"quit\":\n",
        "            print(f'{name}님 대화를 종료하겠습니다.🙋')\n",
        "            break\n",
        "        conversation_data_emobot['emobot_utterance'] = emobot_utterance\n",
        "\n",
        "        emobot_response = \"\"\n",
        "        while True:\n",
        "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(\"<usr>\"+ emobot_utterance + \"<unused1>\" + \"<sys>\" + emobot_response)).unsqueeze(dim=0).to(device)\n",
        "            pred = model_GPT(input_ids)\n",
        "            pred = pred.logits\n",
        "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
        "            if gen == \"</s>\":\n",
        "                break\n",
        "            emobot_response += gen.replace(\"▁\", \" \")\n",
        "            if \"00\" in emobot_response:\n",
        "                emobot_response = emobot_response.replace(\"00\", \"사용자\")\n",
        "\n",
        "        emoticons = emoticon_predict(emobot_response)\n",
        "        if \"감사\" in emobot_response:\n",
        "            emoticons = [random.choice(emoticon_label['happy'])]\n",
        "        emoticons_str = ' '.join(emoticons)\n",
        "        response_with_emoticons = emobot_response + emoticons_str\n",
        "        all_emobot_conversation.append(response_with_emoticons)\n",
        "        conversation_data_emobot['emobot_response'] = response_with_emoticons\n",
        "\n",
        "        print(\"EmoBot > {}\".format(response_with_emoticons.strip()))\n",
        "        print(\"\\n\")\n",
        "        # 대화 데이터를 CSV 파일에 추가\n",
        "        save_conversation_to_csv(conversation_data_emobot)\n",
        "\n",
        "# CSV 파일 닫기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXO34dD87kLe"
      },
      "outputs": [],
      "source": [
        "# 아래 코드는 어떤 문장이든지 이모티콘 붙임\n",
        "# 정확도가 낮은 경우가 있음\n",
        "\n",
        "# responses with emojis\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "# 모델을 GPU로 이동\n",
        "model_GPT.to('cuda:0')\n",
        "\n",
        "import csv\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file = '/content/drive/MyDrive/study/EmoBot/우울증/3.result/emobot_result(wellness, songys, corpus).csv'\n",
        "\n",
        "# CSV 파일에 대화 데이터 저장을 위한 함수\n",
        "def save_conversation_to_csv(conversation_data_emobot):\n",
        "    with open(csv_file, 'a', newline='') as file:\n",
        "        fieldnames = ['emobot_utterance', 'emobot_response']\n",
        "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "        if file.tell() == 0:  # 파일이 비어 있는 경우에만 헤더를 작성\n",
        "            writer.writeheader()\n",
        "        writer.writerow(conversation_data_emobot)\n",
        "\n",
        "# 대화 데이터 초기화\n",
        "conversation_data_emobot = {\n",
        "    'emobot_utterance': '',\n",
        "    'emobot_response': '',\n",
        "}\n",
        "\n",
        "# 경고 무시 설정\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "#대화 예시 추출하기\n",
        "#KoGPT2 + Emoji\n",
        "print('안녕하세요!\\n')\n",
        "name = str(input(\"사용자님의 성함을 말씀해주세요:\"))\n",
        "print(\"\\n\")\n",
        "print(f'{name}님 안녕하세요.😊\\nEmoBot🤖과 함께 대화를 나눠보아요.\\n대화 종료를 원할 경우, quit를 입력해주세요.')\n",
        "print(\"\\n\")\n",
        "all_emobot_conversation = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    while True:\n",
        "        emobot_utterance = input(\"user > \").strip()\n",
        "        all_emobot_conversation.append(emobot_utterance)\n",
        "        if emobot_utterance == \"quit\":\n",
        "          print(f'{name}님 대화를 종료하겠습니다.🙋')\n",
        "          break\n",
        "        conversation_data_emobot['emobot_utterance'] = emobot_utterance\n",
        "\n",
        "        emobot_response = \"\"\n",
        "        while True:\n",
        "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(\"<usr>\"+ emobot_utterance + \"<unused1>\" + \"<sys>\" + emobot_response)).unsqueeze(dim=0).to(device)\n",
        "            pred = model_GPT(input_ids)\n",
        "            pred = pred.logits\n",
        "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
        "            if gen == \"</s>\":\n",
        "                break\n",
        "            emobot_response += gen.replace(\"▁\", \" \")\n",
        "            if \"00\" in emobot_response:\n",
        "              emobot_response = emobot_response.replace(\"00\", \"사용자\")\n",
        "            # if \"감사\" in emobot_response:\n",
        "            #   emobot_response = \"감사합니다 😊\"\n",
        "        emoticons = emoticon_predict(emobot_response)  # 감정 이모티콘을 얻어옴\n",
        "        if \"감사\" in emobot_response:\n",
        "            # \"감사\"가 포함된 경우, \"happy\" 감정에 해당하는 이모티콘 중 하나를 랜덤으로 선택\n",
        "            emoticons = [random.choice(emoticon_label['happy'])]\n",
        "        else:\n",
        "            # \"감사\"가 포함되지 않은 경우, 앞서 얻어온 감정 이모티콘 사용\n",
        "            emoticons_str = ' '.join(emoticons)\n",
        "        emoticons_str = ' '.join(emoticons)  # 이모티콘을 문자열로 변환\n",
        "        response_with_emoticons = emobot_response + emoticons_str  # 이모티콘을 응답에 추가\n",
        "        all_emobot_conversation.append(response_with_emoticons)\n",
        "        conversation_data_emobot['emobot_response'] = response_with_emoticons\n",
        "\n",
        "        print(\"EmoBot > {}\".format(response_with_emoticons.strip()))\n",
        "        print(\"\\n\")\n",
        "        # 대화 데이터를 CSV 파일에 추가\n",
        "        save_conversation_to_csv(conversation_data_emobot)\n",
        "\n",
        "# CSV 파일 닫기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# KoBERT 토크나이저와 모델 불러오기\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "model = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
        "\n",
        "class RegressionNet(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(RegressionNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "def predict_vad(dlg_emotion, label_emotion, dlg_vad):\n",
        "    # model_name = f\"{dlg_emotion}_to_{label_emotion}_regression.pt\"\n",
        "    model_path = os.path.join('/content/drive/MyDrive/study/EmoBot/우울증/2.code/kobert_classifier_model.pth')\n",
        "\n",
        "    model = RegressionNet(input_dim=3)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor(np.array([dlg_vad]), dtype=torch.float32)\n",
        "        predicted_vad = model(input_tensor).numpy()[0]\n",
        "\n",
        "    return predicted_vad\n",
        "\n",
        "def get_vad(dlg_emotion, label_emotion, dlg_vad):\n",
        "    predicted_vad = predict_vad(dlg_emotion, label_emotion, dlg_vad)\n",
        "    return predicted_vad\n",
        "\n",
        "def vad_regression(emo):\n",
        "    # 이 함수는 감정 벡터(emo)를 입력으로 받아 VAD 값을 예측하는 함수입니다.\n",
        "    # 실제로는 VAD 값을 예측하기 위한 회귀 모델을 사용해야 합니다.\n",
        "    # 아래는 더미 값으로 VAD를 생성하는 예제입니다.\n",
        "\n",
        "    # 각 VAD 차원을 더미 값으로 설정\n",
        "    valence = 0.7\n",
        "    arousal = 0.6\n",
        "    dominance = 0.8\n",
        "\n",
        "    return [valence, arousal, dominance]\n",
        "\n",
        "# SimpleReg 모델 생성\n",
        "model = RegressionNet()\n",
        "\n",
        "# 학습된 가중치 불러오기\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/kobert_classifier_model.pth'))\n",
        "\n",
        "# 나머지 코드 실행\n",
        "csv_file_path = '/content/drive/MyDrive/study/EmoBot/우울증/3.result/kogpt2_result_crawling.csv'\n",
        "\n",
        "# CSV 파일 불러오기\n",
        "df2 = pd.read_csv(csv_file_path)\n",
        "\n",
        "# 리워드 함수 정의 (with emoji)\n",
        "def get_reward_for_response(response, prev_response, correct_emotion, dlg_emotion, correct_emotion_accuracy=0.8):\n",
        "    # 1. 답변 길이에 대한 리워드 (0~10점)\n",
        "    length_reward = max(0, min(10, 10 - abs(len(response) - 20) / 2))\n",
        "\n",
        "    # 2. 이전과 동일한 답변에 대한 패널티 (0~10점)\n",
        "    repetition_penalty = max(0, min(10, 10 - int(response == prev_response)))\n",
        "\n",
        "    # 3. 감정 분류 이모티콘에 대한 리워드 (0~10점)\n",
        "    correct_emotion_reward = max(0, min(10, 10 * correct_emotion_accuracy * correct_emotion))\n",
        "\n",
        "    # 4. VAD 예측에 대한 리워드 (0~10점)\n",
        "    # 아래 코드는 더미 값으로 VAD를 가져오는 부분입니다.\n",
        "    dlg_vad = vad_regression(dlg_emotion)\n",
        "    pre_vad = get_vad(dlg_emotion, correct_emotion, dlg_vad)\n",
        "    vad_reward = max(0, min(10, 10 * np.dot(pre_vad, dlg_vad)))\n",
        "\n",
        "    # 전체 리워드 계산 (총 40점 만점)\n",
        "    total_reward = length_reward + repetition_penalty + correct_emotion_reward + vad_reward\n",
        "\n",
        "    return total_reward\n",
        "\n",
        "# 초기값 설정\n",
        "prev_response = None  # 이전 답변이 없을 경우 None으로 설정\n",
        "\n",
        "# 리워드 계산 및 출력\n",
        "for index, row in df2.iterrows():\n",
        "    response = row['kogpt2_response']\n",
        "    dlg_emotion = row['dlg_emotion']\n",
        "\n",
        "    # 리워드 계산\n",
        "    reward = get_reward_for_response(response, prev_response, correct_emotion, dlg_emotion)\n",
        "\n",
        "    # 결과 출력 (혹은 저장)\n",
        "    print(f\"Response: {response}, Total Reward: {reward}\")\n",
        "\n",
        "    # 다음 반복을 위해 이전 답변 업데이트\n",
        "    prev_response = response\n"
      ],
      "metadata": {
        "id": "_UI7Pezs0Jzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# KoBERT 토크나이저와 모델 불러오기\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "model = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
        "\n",
        "class RegressionNet(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(RegressionNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "def predict_vad(dlg_emotion, label_emotion, dlg_vad):\n",
        "    # model_name = f\"{dlg_emotion}_to_{label_emotion}_regression.pt\"\n",
        "    model_path = os.path.join('/content/drive/MyDrive/study/EmoBot/우울증/2.code/kobert_classifier_model.pth')\n",
        "\n",
        "    model = RegressionNet(input_dim=3)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor(np.array([dlg_vad]), dtype=torch.float32)\n",
        "        predicted_vad = model(input_tensor).numpy()[0]\n",
        "\n",
        "    return predicted_vad\n",
        "\n",
        "def get_vad(dlg_emotion, label_emotion, dlg_vad):\n",
        "    predicted_vad = predict_vad(dlg_emotion, label_emotion, dlg_vad)\n",
        "    return predicted_vad\n",
        "\n",
        "def vad_regression(emo):\n",
        "    # 이 함수는 감정 벡터(emo)를 입력으로 받아 VAD 값을 예측하는 함수입니다.\n",
        "    # 실제로는 VAD 값을 예측하기 위한 회귀 모델을 사용해야 합니다.\n",
        "    # 아래는 더미 값으로 VAD를 생성하는 예제입니다.\n",
        "\n",
        "    # 각 VAD 차원을 더미 값으로 설정\n",
        "    valence = 0.7\n",
        "    arousal = 0.6\n",
        "    dominance = 0.8\n",
        "\n",
        "    return [valence, arousal, dominance]\n",
        "\n",
        "# SimpleReg 모델 생성\n",
        "model = RegressionNet()\n",
        "\n",
        "# 학습된 가중치 불러오기\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/study/EmoBot/우울증/2.code/kobert_classifier_model.pth'))\n",
        "\n",
        "# 나머지 코드 실행\n",
        "csv_file_path = '/content/drive/MyDrive/study/EmoBot/우울증/3.result/emoobot_result_crawling.csv'\n",
        "\n",
        "# CSV 파일 불러오기\n",
        "df2 = pd.read_csv(csv_file_path)\n",
        "\n",
        "# 리워드 함수 정의 (with emoji)\n",
        "def get_reward_for_response(response, prev_response, correct_emotion, dlg_emotion, correct_emotion_accuracy=0.8):\n",
        "    # 1. 답변 길이에 대한 리워드 (0~10점)\n",
        "    length_reward = max(0, min(10, 10 - abs(len(response) - 20) / 2))\n",
        "\n",
        "    # 2. 이전과 동일한 답변에 대한 패널티 (0~10점)\n",
        "    repetition_penalty = max(0, min(10, 10 - int(response == prev_response)))\n",
        "\n",
        "    # 3. 감정 분류 이모티콘에 대한 리워드 (0~10점)\n",
        "    correct_emotion_reward = max(0, min(10, 10 * correct_emotion_accuracy * correct_emotion))\n",
        "\n",
        "    # 4. VAD 예측에 대한 리워드 (0~10점)\n",
        "    # 아래 코드는 더미 값으로 VAD를 가져오는 부분입니다.\n",
        "    dlg_vad = vad_regression(dlg_emotion)\n",
        "    pre_vad = get_vad(dlg_emotion, correct_emotion, dlg_vad)\n",
        "    vad_reward = max(0, min(10, 10 * np.dot(pre_vad, dlg_vad)))\n",
        "\n",
        "    # 전체 리워드 계산 (총 40점 만점)\n",
        "    total_reward = length_reward + repetition_penalty + correct_emotion_reward + vad_reward\n",
        "\n",
        "    return total_reward\n",
        "\n",
        "# 초기값 설정\n",
        "prev_response = None  # 이전 답변이 없을 경우 None으로 설정\n",
        "\n",
        "# 리워드 계산 및 출력\n",
        "for index, row in df2.iterrows():\n",
        "    response = row['emobot_response']\n",
        "    dlg_emotion = row['dlg_emotion']\n",
        "\n",
        "    # 리워드 계산\n",
        "    reward = get_reward_for_response(response, prev_response, correct_emotion, dlg_emotion)\n",
        "\n",
        "    # 결과 출력 (혹은 저장)\n",
        "    print(f\"Response: {response}, Total Reward: {reward}\")\n",
        "\n",
        "    # 다음 반복을 위해 이전 답변 업데이트\n",
        "    prev_response = response\n"
      ],
      "metadata": {
        "id": "62bkbCmc0P67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdy9sy3nLdib"
      },
      "outputs": [],
      "source": [
        "# #우선 보류\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# # CSV 파일 경로\n",
        "# csv_file_path = '/content/drive/MyDrive/study/EmoBot/우울증/3.result/emoobot_result_crawling.csv'\n",
        "\n",
        "# # CSV 파일 불러오기\n",
        "# df2 = pd.read_csv(csv_file_path)\n",
        "\n",
        "# # 첫 번째 행을 헤더로 설정\n",
        "# df2\n",
        "\n",
        "# # 리워드 함수 정의 (with emoji)\n",
        "# def get_reward_for_response(response, prev_response, correct_emotion):\n",
        "#     # 1. 답변 길이에 대한 리워드 (0~10점)\n",
        "#     length_reward = max(0, min(10, 10 - abs(len(response) - 20) / 2))\n",
        "\n",
        "#     # 2. 이전과 동일한 답변에 대한 패널티 (0~10점)\n",
        "#     repetition_penalty = max(0, min(10, 10 - int(response == prev_response)))\n",
        "\n",
        "#     # 3. 감정 분류 이모티콘에 대한 리워드 (0~10점)\n",
        "#     correct_emotion_reward = max(0, min(10, 10 * correct_emotion))\n",
        "\n",
        "#     # 전체 리워드 계산 (총 30점 만점)\n",
        "#     total_reward = length_reward + repetition_penalty + correct_emotion_reward\n",
        "\n",
        "#     return total_reward\n",
        "\n",
        "# # 초기값 설정\n",
        "# prev_response = None  # 이전 답변이 없을 경우 None으로 설정\n",
        "# correct_emotion = False  # 실제 감정 분류 결과에 따라 수정\n",
        "\n",
        "# # 리워드 계산 및 출력\n",
        "# for index, row in df2.iterrows():\n",
        "#     response = row['emobot_response']\n",
        "\n",
        "#     # 리워드 계산\n",
        "#     reward = get_reward_for_response(response, prev_response, correct_emotion)\n",
        "\n",
        "#     # 결과 출력 (혹은 저장)\n",
        "#     print(f\"Response: {response}, Total Reward: {reward}\")\n",
        "\n",
        "#     # 다음 반복을 위해 이전 답변 업데이트\n",
        "#     prev_response = response"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WwbkC7Vanw5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQ/ik7xyKI7DubgzGSfoZi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45cbedd489e14212bf9bcb9dc5a62f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae91b7224dcd44ef8ace2901a775da4c",
              "IPY_MODEL_1b3151483dd546afabb1bdfe8661914b",
              "IPY_MODEL_e2bdc8da308e4feca349fc75e194f351"
            ],
            "layout": "IPY_MODEL_3593dabf91a54f8c9e39f47d2cbce4da"
          }
        },
        "ae91b7224dcd44ef8ace2901a775da4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_409ab0c5abba4d6680d905452d1bb57d",
            "placeholder": "​",
            "style": "IPY_MODEL_17dcea2ede8f4c20814d6f8e14bf96db",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1b3151483dd546afabb1bdfe8661914b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3faca4943b941ac872bdc2ded9e7bb0",
            "max": 432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73eae158bfaa402e94dbdc3024d71db3",
            "value": 432
          }
        },
        "e2bdc8da308e4feca349fc75e194f351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb90b222032449d197130da74c2541a0",
            "placeholder": "​",
            "style": "IPY_MODEL_9d6042f807f143f99b6a40f8a4c2fb34",
            "value": " 432/432 [00:00&lt;00:00, 36.0kB/s]"
          }
        },
        "3593dabf91a54f8c9e39f47d2cbce4da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409ab0c5abba4d6680d905452d1bb57d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17dcea2ede8f4c20814d6f8e14bf96db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3faca4943b941ac872bdc2ded9e7bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73eae158bfaa402e94dbdc3024d71db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb90b222032449d197130da74c2541a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d6042f807f143f99b6a40f8a4c2fb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1b75b80cd034c5db775d06b8334f6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42e67c36ac4b4e2eb9e5400e5706ace8",
              "IPY_MODEL_5b79ebbc25d64f33a8bcb42298a4036d",
              "IPY_MODEL_6acd44385a084dd1b45c5bbb6a0b4699"
            ],
            "layout": "IPY_MODEL_e5e4706c0b824e7abc51bea5462b7209"
          }
        },
        "42e67c36ac4b4e2eb9e5400e5706ace8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_180e0b5de7d94fd290074cbfb5172fbf",
            "placeholder": "​",
            "style": "IPY_MODEL_4e6926d5c66443fe972be4e99a5b5c5a",
            "value": "spiece.model: 100%"
          }
        },
        "5b79ebbc25d64f33a8bcb42298a4036d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9118ae0d0cc47ee822b894e60b2da89",
            "max": 371427,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7215d11003e542f9b809da4a08740967",
            "value": 371427
          }
        },
        "6acd44385a084dd1b45c5bbb6a0b4699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b0e8fb7d0e64af9b4053f19976454de",
            "placeholder": "​",
            "style": "IPY_MODEL_8a648b9e904446b38548aa1b98fd99f0",
            "value": " 371k/371k [00:00&lt;00:00, 3.60MB/s]"
          }
        },
        "e5e4706c0b824e7abc51bea5462b7209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180e0b5de7d94fd290074cbfb5172fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6926d5c66443fe972be4e99a5b5c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9118ae0d0cc47ee822b894e60b2da89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7215d11003e542f9b809da4a08740967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b0e8fb7d0e64af9b4053f19976454de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a648b9e904446b38548aa1b98fd99f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f2b844344ac40f5a81d6a872cf05a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d89744cb2364b3bb70da385af3165ce",
              "IPY_MODEL_dac026d5bc9c4dadb151c452663c544b",
              "IPY_MODEL_297a90d4c4cc44f5853c2871825cb90a"
            ],
            "layout": "IPY_MODEL_aa89ef83a4714d55a929404d29278dc7"
          }
        },
        "7d89744cb2364b3bb70da385af3165ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67489c89ab10406297c7b8aa819d86ad",
            "placeholder": "​",
            "style": "IPY_MODEL_615fbe87113348378acdd0467a2db663",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "dac026d5bc9c4dadb151c452663c544b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0288048dbac342cd8d703c5e38a95392",
            "max": 244,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3fe1bc9c80d450db31640dbf2784c85",
            "value": 244
          }
        },
        "297a90d4c4cc44f5853c2871825cb90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3b36cb6214415683419509bb3dce42",
            "placeholder": "​",
            "style": "IPY_MODEL_d8874a42e1e74fc9a4868d4b421e18b7",
            "value": " 244/244 [00:00&lt;00:00, 21.1kB/s]"
          }
        },
        "aa89ef83a4714d55a929404d29278dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67489c89ab10406297c7b8aa819d86ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615fbe87113348378acdd0467a2db663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0288048dbac342cd8d703c5e38a95392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3fe1bc9c80d450db31640dbf2784c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f3b36cb6214415683419509bb3dce42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8874a42e1e74fc9a4868d4b421e18b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51cbbcda0ce84d92962cb3af133c5ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ef658b4e1454646bdbcf252941f7ce4",
              "IPY_MODEL_657f4e744dea408492df0bf136268300",
              "IPY_MODEL_b809c6f657bb48f08b820b16d186a495"
            ],
            "layout": "IPY_MODEL_ea10927e554b4843a111d1d375e9c21c"
          }
        },
        "7ef658b4e1454646bdbcf252941f7ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0c37c25fa14de8a9a1da4522fcd91c",
            "placeholder": "​",
            "style": "IPY_MODEL_afd1fc6c76524e008afe57e42fc99819",
            "value": "config.json: 100%"
          }
        },
        "657f4e744dea408492df0bf136268300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830d49621a4e43279d9ce83d88e3eacc",
            "max": 535,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d843ec958df4f958d2f40754d4551eb",
            "value": 535
          }
        },
        "b809c6f657bb48f08b820b16d186a495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4a30c641464ba2b718be8c8a167d90",
            "placeholder": "​",
            "style": "IPY_MODEL_fbfcce981fa04bbba3565e4fa6d2b906",
            "value": " 535/535 [00:00&lt;00:00, 47.6kB/s]"
          }
        },
        "ea10927e554b4843a111d1d375e9c21c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd0c37c25fa14de8a9a1da4522fcd91c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd1fc6c76524e008afe57e42fc99819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "830d49621a4e43279d9ce83d88e3eacc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d843ec958df4f958d2f40754d4551eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd4a30c641464ba2b718be8c8a167d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfcce981fa04bbba3565e4fa6d2b906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d387077b52074a35ae9f181db38fbdf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_271fe8ac1cac406faad2cb479d712b67",
              "IPY_MODEL_f7d682d50a5d43cfbb15d4227ecb370c",
              "IPY_MODEL_862f4bc125b14b66a77d245bc3c5843c"
            ],
            "layout": "IPY_MODEL_36e62cdd90e1414c8940f7c0f3b521db"
          }
        },
        "271fe8ac1cac406faad2cb479d712b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ba85958b354dc3885f1cddfb508d11",
            "placeholder": "​",
            "style": "IPY_MODEL_8dcafb7bf42b41969d8ceb2d44633c2d",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f7d682d50a5d43cfbb15d4227ecb370c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a07afa82c147058c3552df7d668bbc",
            "max": 368792544,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acdf3535d41c45d48280bbfd564bc736",
            "value": 368792544
          }
        },
        "862f4bc125b14b66a77d245bc3c5843c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_956ba4bdd2a048229bbc8942ad981d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_333a58a3d87e4ca1bb2f9179d23fc8d4",
            "value": " 369M/369M [00:02&lt;00:00, 148MB/s]"
          }
        },
        "36e62cdd90e1414c8940f7c0f3b521db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ba85958b354dc3885f1cddfb508d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dcafb7bf42b41969d8ceb2d44633c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0a07afa82c147058c3552df7d668bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acdf3535d41c45d48280bbfd564bc736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "956ba4bdd2a048229bbc8942ad981d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "333a58a3d87e4ca1bb2f9179d23fc8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}